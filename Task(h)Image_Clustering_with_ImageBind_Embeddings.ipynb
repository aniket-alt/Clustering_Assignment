{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODf+Sin7MPaGRqrd2fHW4N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniket-alt/Clustering_Assignment/blob/main/Task(h)Image_Clustering_with_ImageBind_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task (h): Image Clustering with ImageBind Embeddings\n",
        "\n",
        "In this task, we move beyond simple color and texture analysis. We use ImageBind as a sophisticated feature extractor for visual data. Traditional image clustering often struggles with variations in lighting, angles, or background. However, by using ImageBind’s Vision Transformer (ViT) backbone, we convert images into high-level semantic embeddings. This allows our clustering algorithm to group images based on the objects and concepts they contain (e.g., 'a vehicle' vs. 'an animal') rather than just similar pixel distributions."
      ],
      "metadata": {
        "id": "O3w1CY7n1V4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFfWpHWvtfM3",
        "outputId": "8c699215-d72a-4608-9d25-6909cf64fa9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.9.1+cu126)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (6.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
            "/content\n",
            "Cloning into 'ImageBind'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 187 (delta 84), reused 54 (delta 53), pack-reused 67 (from 3)\u001b[K\n",
            "Receiving objects: 100% (187/187), 2.65 MiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "/content/ImageBind\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for imagebind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.47G/4.47G [08:14<00:00, 9.71MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "IMAGE CLUSTERING SUCCESSFUL\n",
            "========================================\n",
            "Dog                  -> Cluster 0\n",
            "Bird                 -> Cluster 0\n",
            "Car                  -> Cluster 1\n"
          ]
        }
      ],
      "source": [
        "# --- 1. SYSTEM-LEVEL INJECTION (Fixes the ModuleNotFoundError) ---\n",
        "!pip install torchcodec --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install ftfy\n",
        "\n",
        "# --- 1. SYSTEM-LEVEL INJECTION ---\n",
        "import sys\n",
        "import torchvision.transforms.functional as F\n",
        "from types import ModuleType\n",
        "\n",
        "# Fix the torchvision bug before anything else starts\n",
        "mock_module = ModuleType(\"torchvision.transforms.functional_tensor\")\n",
        "mock_module.__dict__.update(F.__dict__)\n",
        "sys.modules[\"torchvision.transforms.functional_tensor\"] = mock_module\n",
        "\n",
        "# --- 2. ENVIRONMENT SETUP ---\n",
        "import os\n",
        "%cd /content\n",
        "!rm -rf ImageBind\n",
        "!git clone https://github.com/facebookresearch/ImageBind.git\n",
        "%cd ImageBind\n",
        "!pip install pytorchvideo timm fvcore -q\n",
        "!pip install . --no-deps -q\n",
        "\n",
        "# --- 3. IMPORTS ---\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from imagebind import data\n",
        "from imagebind.models import imagebind_model\n",
        "from imagebind.models.imagebind_model import ModalityType\n",
        "from PIL import Image\n",
        "\n",
        "# --- 4. LOAD MODEL ---\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# --- 5. DATA PREPARATION ---\n",
        "os.makedirs(\"task_h_images\", exist_ok=True)\n",
        "urls = {\n",
        "    \"Dog\": \"https://raw.githubusercontent.com/facebookresearch/ImageBind/main/.assets/dog_image.jpg\",\n",
        "    \"Bird\": \"https://raw.githubusercontent.com/facebookresearch/ImageBind/main/.assets/bird_image.jpg\",\n",
        "    \"Car\": \"https://raw.githubusercontent.com/facebookresearch/ImageBind/main/.assets/car_image.jpg\"\n",
        "}\n",
        "\n",
        "valid_paths = []\n",
        "processed_names = []\n",
        "\n",
        "for name, url in urls.items():\n",
        "    path = f\"task_h_images/{name}.jpg\"\n",
        "    !wget -O {path} {url} -q\n",
        "    try:\n",
        "        with Image.open(path) as img:\n",
        "            img.verify()\n",
        "            valid_paths.append(path)\n",
        "            processed_names.append(name)\n",
        "    except:\n",
        "        print(f\"Skipping {name} due to download error.\")\n",
        "\n",
        "# --- 6. EXECUTION ---\n",
        "with torch.no_grad():\n",
        "    inputs = {ModalityType.VISION: data.load_and_transform_vision_data(valid_paths, device)}\n",
        "    embeddings = model(inputs)\n",
        "    vis_emb = embeddings[ModalityType.VISION].cpu().numpy()\n",
        "\n",
        "# Cluster into 2 groups\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(vis_emb)\n",
        "\n",
        "# --- 7. OUTPUT ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"IMAGE CLUSTERING SUCCESSFUL\")\n",
        "print(\"=\"*40)\n",
        "for i, name in enumerate(processed_names):\n",
        "    print(f\"{name.ljust(20)} -> Cluster {labels[i]}\")"
      ]
    }
  ]
}