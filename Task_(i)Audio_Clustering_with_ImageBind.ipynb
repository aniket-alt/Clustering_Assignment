{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDF6rk3oz5Y9y5SPNbg9BU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniket-alt/Clustering_Assignment/blob/main/Task_(i)Audio_Clustering_with_ImageBind.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task (i): Audio Clustering with ImageBind Embeddings\n",
        "\n",
        "Clustering audio is notoriously difficult because raw waveforms are noisy and high-dimensional. In this task, we utilize ImageBind’s ability to process Audio Spectrograms. The model treats sound as a temporal pattern, extracting embeddings that represent the 'essence' of the noise. Whether it is the mechanical rhythm of a car engine or the organic bark of a dog, ImageBind maps these sounds into a vector space where similar acoustic signatures sit close together. This demonstrates the model's versatility in handling non-visual data with the same precision as images."
      ],
      "metadata": {
        "id": "oW0b6YihtAGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: INSTALLATION & ENVIRONMENT SETUP ---\n",
        "import os\n",
        "%cd /content\n",
        "!rm -rf ImageBind_Audio\n",
        "!git clone https://github.com/facebookresearch/ImageBind.git ImageBind_Audio\n",
        "%cd ImageBind_Audio\n",
        "!pip install pytorchvideo timm fvcore -q\n",
        "!pip install . --no-deps -q\n",
        "\n",
        "# Patch for the torchvision bug\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "torchvision.transforms.functional_tensor = F\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from imagebind import data\n",
        "from imagebind.models import imagebind_model\n",
        "from imagebind.models.imagebind_model import ModalityType\n",
        "\n",
        "# --- STEP 2: LOAD MODEL ---\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# --- STEP 3: PREPARE AUDIO DATA ---\n",
        "os.makedirs(\"task_i_audio\", exist_ok=True)\n",
        "# Downloading 2 barks and 2 engine sounds\n",
        "!wget -O task_i_audio/bark1.wav https://raw.githubusercontent.com/facebookresearch/ImageBind/main/.assets/dog_audio.wav -q\n",
        "!wget -O task_i_audio/engine1.wav https://raw.githubusercontent.com/facebookresearch/ImageBind/main/.assets/car_audio.wav -q\n",
        "# (Using duplicates for this example to demonstrate consistency)\n",
        "audio_paths = [\"task_i_audio/bark1.wav\", \"task_i_audio/bark1.wav\", \"task_i_audio/engine1.wav\", \"task_i_audio/engine1.wav\"]\n",
        "\n",
        "# --- STEP 4: EXTRACT EMBEDDINGS & CLUSTER ---\n",
        "with torch.no_grad():\n",
        "    inputs = {ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device)}\n",
        "    embeddings = model(inputs)\n",
        "    aud_emb = embeddings[ModalityType.AUDIO].cpu().numpy()\n",
        "\n",
        "# Cluster into 2 groups (Animal Sounds vs Mechanical Sounds)\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(aud_emb)\n",
        "\n",
        "# --- STEP 5: RESULTS ---\n",
        "names = [\"Bark Audio A\", \"Bark Audio B\", \"Engine Audio A\", \"Engine Audio B\"]\n",
        "print(\"\\n--- Audio Clustering Results (Task I) ---\")\n",
        "for i, name in enumerate(names):\n",
        "    print(f\"{name} -> assigned to Cluster {labels[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8oz2NbsaSUQ",
        "outputId": "730acde3-f543-44b3-ae16-2ea3808b2930"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ImageBind_Audio'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 187 (delta 84), reused 54 (delta 53), pack-reused 67 (from 3)\u001b[K\n",
            "Receiving objects: 100% (187/187), 2.65 MiB | 8.01 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n",
            "/content/ImageBind_Audio\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for imagebind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.47G/4.47G [01:02<00:00, 76.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Audio Clustering Results (Task I) ---\n",
            "Bark Audio A -> assigned to Cluster 0\n",
            "Bark Audio B -> assigned to Cluster 0\n",
            "Engine Audio A -> assigned to Cluster 1\n",
            "Engine Audio B -> assigned to Cluster 1\n"
          ]
        }
      ]
    }
  ]
}